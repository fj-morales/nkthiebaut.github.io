{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-shot learning on textual data with siamese neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're doing machine learning and meet a classification problem with many categories and few examples per category, it is usually thought that you're in trouble. Unfortunately, acquiring new data to solve this issue is not always easy or even doable.\n",
    "\n",
    "This problem of learning with only a few examples per category is called \"few-shot learning\", and \"one-shot learning\" in the extreme case of only one example per class (yes, you can even do this and [obtain decent results](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)!). \n",
    "\n",
    "Most of the machine learning research on one-shot learning involves images, but some [recent research papers](https://arxiv.org/abs/1710.10280) address the same problem in the Natural Language Processing (NLP) realm.\n",
    "\n",
    "In this blog post, I will use siamese neural network to tackle few-shot learning , following a [method that was originally applied to images](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) and that is nicely explained [here](https://sorenbouma.github.io/blog/oneshot/).\n",
    "\n",
    "A nice example of a few-shot learning problem in NLP is job title classification. If you want to group job titles in different categories or \"occupations\" (e.g. gather \"Programmer\" and \"Software engineer\" in an occupation, and \" in another one), then unless you have hundreds of job titles examples per occupation you are facing a few-shot learning problem. The U.S government provides such a job title taxonomy: the [Standard Occupational Classification](https://www.bls.gov/soc/). I'll use it as a toy dataset understand how few-shot learning with siamese neural networks works.\n",
    "\n",
    "Let's start by downloading the taxonomy and check what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Reported Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Diversity Officer (CDO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executive Officer (CEO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Financial Officer (CFO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Nursing Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Operating Officer (COO)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  O*NET-SOC Code             Reported Job Title\n",
       "0     11-1011.00  Chief Diversity Officer (CDO)\n",
       "1     11-1011.00  Chief Executive Officer (CEO)\n",
       "2     11-1011.00  Chief Financial Officer (CFO)\n",
       "3     11-1011.00          Chief Nursing Officer\n",
       "4     11-1011.00  Chief Operating Officer (COO)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Download the Standard Occupation Classification\n",
    "file_url = 'https://www.onetcenter.org/dl_files/database/db_20_1_text/Sample%20of%20Reported%20Titles.txt'\n",
    "csv = StringIO(requests.get(file_url).text)\n",
    "\n",
    "# Load it in a pandas DataFrame and drop a useless column\n",
    "df = pd.read_csv(csv, sep='\\t').drop('Shown in My Next Move', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded file contains job categories codes (first column) and samples of job titles that belong to those categories. To get categories description type the occupation code [here](https://www.onetonline.org/help/online/search). For instance, the first occupation (11-1011.00) is called \"Chief Executives\" as one can guess from the corresponding job titles examples.\n",
    "\n",
    "Let's investigate a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O*NET-SOC Code         956\n",
       "Reported Job Title    7174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()  # Count the number of different modalities in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 956 categories (\"occupations\") for 7174 examples, i.e. 7.5 examples per category on average. We are definitely in the few-shot learning setting. \n",
    "\n",
    "Before proceeding with modelling let's create a train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['Reported Job Title'] = df['Reported Job Title'].str.lower()\n",
    "occupations = df['O*NET-SOC Code'].unique()\n",
    "occupations_train, occupations_test = train_test_split(occupations, test_size=0.2)\n",
    "df_train = df[df['O*NET-SOC Code'].isin(occupations_train)]\n",
    "df_test = df[df['O*NET-SOC Code'].isin(occupations_test)]\n",
    "x_train, y_train = df_train['Reported Job Title'], df_train['O*NET-SOC Code']\n",
    "x_test, y_test = df_test['Reported Job Title'], df_test['O*NET-SOC Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a baseline\n",
    "\n",
    "Before experimenting with fancy models, let's establish a strong baseline. We can start by using word embeddings to get a vector representation of each job title, and use a nearest neighbor classifier that is a less likely to overfit than tree-based models or parametric classifiers.\n",
    "\n",
    "To get the representation of a sentence from pre-trained word embeddings I'll use [Zeugma](https://github.com/nkthiebaut/zeugma), an NLP python library I've written that provides pre-trained word embeddings in the form [scikit-learn transformers](http://scikit-learn.org/stable/modules/pipeline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeugma import EmbeddingTransformer\n",
    "\n",
    "# We'll use the GloVe pre-trained embeddings, using the sum of the word embeddings\n",
    "# of a job title as the embedding vector\n",
    "embedding = EmbeddingTransformer('glove', aggregation='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Our model is a nearest neighbor classifier, the input of which is the sum of the \n",
    "# embeddings of words in the job title.\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "baseline = make_pipeline(embedding, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (baseline): 87.18 %\n"
     ]
    }
   ],
   "source": [
    "# Note that the model is fitted directly on the test set,\n",
    "# because it has not adjustable parameters\n",
    "baseline.fit(x_test, y_test)\n",
    "print('Test accuracy (baseline): {:.2f} %'.format(100*baseline.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a simple baseline model, and it may seem hard to beat with a deep learning model due to the high chances of overfitting with such a small datasets, but here come siamese networks to the rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot learning with siamese neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nearest neighbor model of the previous section is preforming quite well despite its simplicity, because it uses word embeddings learnt on the twitter dataset. This is the basic principle of [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).\n",
    "\n",
    "Nevertheless, the embedding space used to determine nearest neighbors knows nothing about job titles in particular. There must be a way to learn an embedding space in which jobs belonging to the same occupation category are closer. This is where siamese networks come into play.\n",
    "\n",
    "The main idea of siamese networks is to learn such a representation by training a model to discriminate between pairs of examples that are in the same category, and pairs of examples that come from different categories. \n",
    "\n",
    "We'll learn about it the next blog article, stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
